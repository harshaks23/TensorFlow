{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running it on the differenet nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_div:  [100 100 100]\n",
      "final_add:  [ 110  200 1100]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([100, 200, 300])\n",
    "y = tf.constant([1, 2, 3])\n",
    "z = tf.placeholder(tf.int32)\n",
    "\n",
    "final_div = tf.div(x, y)\n",
    "\n",
    "final_add = tf.add(final_div, z)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    print (\"final_div: \", sess.run(final_div))\n",
    "    print (\"final_add: \", sess.run(final_add, {z: [10, 100, 1000]}))\n",
    "\n",
    "    writer = tf.summary.FileWriter('./m3_demo1', sess.graph)\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "1.14.5\n",
      "r1: 3.0, r2: 9.0, r3:[81.0]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "a = tf.placeholder(tf.float32, shape=[])\n",
    "b = tf.placeholder(tf.float32, shape=[])\n",
    "c = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "r1 = tf.add(a, b)\n",
    "r2 = tf.multiply(r1, c)\n",
    "r3 = tf.square(r2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # for partial setup there is only fetches and feeds\n",
    "    #Fetches is  something that is it contains all the nodes \n",
    "    #feeds are the placeholders \n",
    "    h = sess.partial_run_setup([r1, r2, r3], [a, b, c])\n",
    "\n",
    "    r1_eval = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
    "\n",
    "    r2_eval = sess.partial_run(h, r2, feed_dict={c: r1_eval})\n",
    "\n",
    "    r3_eval = sess.partial_run(h, [r3])\n",
    "    \n",
    "    print(\"r1: %s, r2: %s, r3:%s\" % (r1_eval, r2_eval, r3_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Store the MNIST data in mnist_data/\n",
    "mnist = input_data.read_data_sets(\"mnist_data/\", one_hot=True)\n",
    "\n",
    "def multilayer_dnn(X):\n",
    "    fc1 = tf.layers.dense(X, 256, activation=tf.nn.relu)\n",
    "    fc2 = tf.layers.dense(fc1, 128, activation=tf.nn.relu)\n",
    "    out = tf.layers.dense(fc2, 10, activation=None)\n",
    "    return out, fc1, fc2\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "y = tf.placeholder(tf.int32, shape=[None, 10])\n",
    "\n",
    "\n",
    "# ### The final output layer with softmax activation\n",
    "#\n",
    "# Do not apply the softmax activation to this layer.\n",
    "# The *tf.nn.sparse_softmax_cross_entropy_with_logits* will apply the\n",
    "# softmax activation as well as calculate the cross-entropy as our cost function\n",
    "\n",
    "logits, fc1, fc2 = multilayer_dnn(X)\n",
    "\n",
    "\n",
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                   labels=y)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "# ### Check correctness and accuracy of the prediction\n",
    "#\n",
    "# * Check whether the highest probability output in logits is equal to the y-label\n",
    "# * Check the accuracy across all predictions (How many predictions did we get right?)\n",
    "\n",
    "correct = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        num_iterations = mnist.train.num_examples // batch_size\n",
    "\n",
    "        for iteration in range(num_iterations):\n",
    "\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            _, loss_eval, fc1_eval, fc2_eval, logits_eval = \\\n",
    "                sess.run([training_op, loss, fc1, fc2, logits],\n",
    "                         feed_dict={X: X_batch, y: y_batch})\n",
    "            if iteration == num_iterations - 1:\n",
    "                print(\"Layer            :  Mean     Standard Deviation\")\n",
    "                print(\"Fully connected 1: \", fc1_eval.mean(), fc1_eval.std())\n",
    "                print(\"Fully connected 2: \", fc2_eval.mean(), fc2_eval.std())\n",
    "\n",
    "\n",
    "        acc_train = accuracy.eval(\n",
    "            feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(\n",
    "            feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
